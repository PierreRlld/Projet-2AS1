{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= pd.read_csv('auteurs_mouvements.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datab = pd.read_csv('Mouvements_wiki_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#je recopie les fonctions de prédiction que je modifie quelque peu (rajout option 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je recharge et modifie les fonctions utiles à la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juste pour ressortir toutes les prédictions \"ex aequo\" dans la fonction suivante\n",
    "\n",
    "def sort_ish(L):\n",
    "    mov,key = L[0]\n",
    "    sorted_final=[mov]\n",
    "    k=1\n",
    "    n=len(L)\n",
    "    while k<n:\n",
    "        mov,keyy=L[k]\n",
    "        if keyy<key:\n",
    "            return sorted_final\n",
    "        else:\n",
    "            sorted_final.append(mov)\n",
    "            k+=1\n",
    "    return sorted_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# name : nom de l'auteur\n",
    "#database : base de données contenant tous les auteurs\n",
    "#train : base de données content tous les mouvements\n",
    "# n : si tf-idf, nombre de mots utilisés dans la liste tf idf\n",
    "# option 1 : tf-idf pour prédire OU texte entier du mouvement 'tf-idf' ou 'texte'\n",
    "# option2 : 'sum' ou 'whole' pour savoir si l'on prend pour l'auteur les données du texte de son summary ou du texte de la page entière\n",
    "\n",
    "\n",
    "def pred(name,database,train,n,option1,option2):\n",
    "    if option1=='tf-idf':\n",
    "        #avec l'option tf-idf, on se base sur les mots les plus importants pour chaque mouvement au sens \n",
    "        #de la métrique tf-idf\n",
    "        if option2=='sum':\n",
    "            txt = database[database['Nom']==name]['sum_lem'].values[0].split()\n",
    "        elif option2=='whole':\n",
    "            txt = database[database['Nom']==name]['page_lem'].values[0].split()\n",
    "            \n",
    "        #on prend le texte associé à l'auteur *name*\n",
    "        \n",
    "        pred={}\n",
    "        #dictionnaire des prédictions\n",
    "        \n",
    "        m=len(train)\n",
    "        \n",
    "        for k in range(m):\n",
    "            #pour chaque mouvement\n",
    "            \n",
    "            mov = train['mouvement'][k] #on récupère son nom\n",
    "            L= eval(train['tf_idf'][k])[:n] #et les n premiers mots tf_idf (n paramètre de la fction)\n",
    "            c=0 #compteur qui va compter combien de mots du texte associé à l'auteur (le summary wikipedia)\n",
    "            #sont des mots présents dans les n tf idf\n",
    "            for keyword in L:\n",
    "                #pour chaque mot clé tf idf\n",
    "                if keyword in txt:\n",
    "                    #s'il est dans le texte associé à l'auteur, on incrémente c.\n",
    "                    c+=1\n",
    "            pred[mov]=c \n",
    "            #le nombre de mots est associé au mouvement dans le dictionnaire\n",
    "        PRED = sorted(pred.items(), key=lambda mot_proba: mot_proba[1])      \n",
    "        PRED.reverse()\n",
    "        #on ordonne le dictionnaire selon les clés\n",
    "        return sort_ish(PRED) #on retourne tous les mots ayant la valeur maximale ! \n",
    "    \n",
    "    \n",
    "    if option1=='texte':\n",
    "        #idem que pour tf-idf sauf qu'on s'intéresse à tout le texte lemmatisé de la page du mouvement \n",
    "        if option2=='sum':\n",
    "            txt = database[database['Nom']==name]['sum_lem'].values[0].split()\n",
    "        elif option2=='whole':\n",
    "            txt = database[database['Nom']==name]['page_lem'].values[0].split()\n",
    "        pred={}\n",
    "        m=len(train)\n",
    "        for k in range(m):\n",
    "            mov = train['mouvement'][k]\n",
    "            L= train['texte_lem'][k].split() #voilà la seule différence : \n",
    "            #on prend comme liste de mots L le texte_lem qui est le texte de la page wiki du mouvement.\n",
    "            c=0\n",
    "            for keyword in L:\n",
    "                if keyword in txt:\n",
    "                    c+=1\n",
    "            pred[mov]=c\n",
    "        PRED = sorted(pred.items(), key=lambda mot_proba: mot_proba[1])\n",
    "        PRED.reverse()\n",
    "        return sort_ish(PRED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je me rends compte que certaines données sont incomplètes : je travaille ainsi pour régler le problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File auteurs_completed_lem.csv does not exist: 'auteurs_completed_lem.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-47a6940af524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'auteurs_completed_lem.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#Je charge la base de données des auteurs complétée qui comporte désormais 622 entrées.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Je remarque que certaines ont NaN dans la colomne censée contenir la page wikipédia de l'auteur ainsi que la page wikipédia lemmatisée.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#C'était en fait du au format de certains noms (écrit avec un _ plutôt qu'un - par ex et impossible pour la bibliothèque de trouver la page wikipédia en conséquence)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File auteurs_completed_lem.csv does not exist: 'auteurs_completed_lem.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('auteurs_completed_lem.csv',index_col=[0])\n",
    "#Je charge la base de données des auteurs complétée qui comporte désormais 622 entrées.\n",
    "#Je remarque que certaines ont NaN dans la colomne censée contenir la page wikipédia de l'auteur ainsi que la page wikipédia lemmatisée.\n",
    "#C'était en fait du au format de certains noms (écrit avec un _ plutôt qu'un - par ex et impossible pour la bibliothèque de trouver la page wikipédia en conséquence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia \n",
    "from wikipedia import WikipediaPage\n",
    "wikipedia.set_lang(\"fr\")\n",
    "#importation des biblis wiki pour recupérer facilement les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# premier traitement disparu pour vérifier qu'une entrée est vide : \n",
    "# c'était data['is_empty]=data['page'].apply(lambda s : int(type(s)==str))\n",
    "data_acompleter = data[data['is_empty']==0]\n",
    "\n",
    "#data_acompleter -> les auteurs dont on a pas récupéré les pages wikipédia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data[data['is_empty']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki(s):\n",
    "    return WikipediaPage(s).content\n",
    "    # associe à une str le contenu de sa page wikipédia associée. On suppose que toutes les entrées correspondent bien à des pages wikipédia (logique ici car les auteurs ont été scrapés sur wikipedia donc tant que rien n'est supprimé, cela fonctionne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-84-3591b3dfc3c5>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_acompleter['page']=data_acompleter['Nom'].apply(wiki)\n"
     ]
    }
   ],
   "source": [
    "data_acompleter['page']=data_acompleter['Nom'].apply(wiki)\n",
    "#je recupère ici "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je sauvegarde les progrès et charge les données utiles à la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acompleter.to_csv('auteurs_incomplete.csv')\n",
    "data_acompleter=pd.read_csv('auteurs_incomplete_completed.csv',index_col=[0])\n",
    "auteurs = pd.concat([data_complete,data_acompleter])\n",
    "auteurs.to_csv('auteurs_complete2.csv')\n",
    "#je sauvegarde puis recharge puis sauvegarde la base de données complète.\n",
    "\n",
    "mouvements=pd.read_csv('Mouvements_wiki_cleaned1.csv',index_col=[0])\n",
    "\n",
    "\n",
    "#je charge les mouvementsdel auteurs['is_empty']\n",
    "auteurs['len']=auteurs['page_lem'].apply(len)\n",
    "\n",
    "authors = list(auteurs['Nom'])\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "database=auteurs\n",
    "train=mouvements\n",
    "n=50\n",
    "#je fixe les arguments pour apporter de la lisibilité.\n",
    "\n",
    "#database : le dataframe contenant les auteurs, le mouvement associé, le summary de leur page wikipédia, leur page wikipédia, et ces contenus lemmatisés également"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=len(authors)\n",
    "predictions = [[] for k in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 622/622 [12:37<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Je choisis chaque combinaison d'option une fois\n",
    "OPT1 = ['tf-idf','texte'] # j'utilise un comptage de mots similaires simples ou bien le comptage de mots en commun avec ceux ressortis par tf-idf\n",
    "OPT2 = ['whole','sum']  # je compare au summary lemmatisé de la page wikipédia ou bien à la page wikipédia lemmatisée entière\n",
    "for k in tqdm(range(m)): #pour tous les auteurs\n",
    "    L=[]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            name = authors[k]\n",
    "            option1 = OPT1[i]\n",
    "            option2 = OPT2[j]\n",
    "            a=pred(name,database,train,n,option1,option2)\n",
    "            L.append(a)\n",
    "    predictions[k]=L\n",
    "            #la liste contient des listes comportant les prédictions avec les différentes options pour chaque auteur\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bac0df5f7923>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mauteurs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;31m#je rajoute la prédiction au dataframe.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# l'ajouter directement avec la méthode .apply m'aurait semblé un peu fouilli, il aurait fallu fixer les arguments dans la fonction ou écrire une autre fonction auxiliaire.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "auteurs['pred']=predictions #je rajoute la prédiction au dataframe.\n",
    "# l'ajouter directement avec la méthode .apply m'aurait semblé un peu fouilli, il aurait fallu fixer les arguments dans la fonction ou écrire une autre fonction auxiliaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom</th>\n",
       "      <th>Mouvement</th>\n",
       "      <th>summary</th>\n",
       "      <th>sum_lem</th>\n",
       "      <th>mvm_label</th>\n",
       "      <th>page</th>\n",
       "      <th>page_lem</th>\n",
       "      <th>len</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William S. Burroughs</td>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>William Seward Burroughs (/ˈwɪljəm ˈsuɚd ˈbɜɹo...</td>\n",
       "      <td>William Seward Burroughs ˈsuɚd dit William Bur...</td>\n",
       "      <td>0</td>\n",
       "      <td>William Seward Burroughs II (; February 5, 191...</td>\n",
       "      <td>William Seward Burroughs ii February 5 1914 au...</td>\n",
       "      <td>61923</td>\n",
       "      <td>[[Beat Generation], [Beat Generation], [symbol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lucien Carr</td>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>Lucien Carr, né le 1er mars 1925 à New York et...</td>\n",
       "      <td>Lucien Carr naître premier mars 1925 New York ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Lucien Carr (March 1, 1925 – January 28, 2005)...</td>\n",
       "      <td>Lucien Carr March 1 1925 January 28 2005 was a...</td>\n",
       "      <td>18339</td>\n",
       "      <td>[[Beat Generation], [Beat Generation, Générati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Clellon Holmes</td>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>John Clellon Holmes est un romancier, essayist...</td>\n",
       "      <td>John Clellon holme romancier essayiste poète a...</td>\n",
       "      <td>0</td>\n",
       "      <td>John Clellon Holmes (March 12, 1926, Holyoke, ...</td>\n",
       "      <td>John Clellon Holmes March 12 1926 Holyoke Mass...</td>\n",
       "      <td>2592</td>\n",
       "      <td>[[Beat Generation], [Génération perdue], [Beat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gregory Corso</td>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>Gregory Nunzio Corso (New York, 26 mars 1930 -...</td>\n",
       "      <td>gregory Nunzio Corso New York 26 mars 1930 Min...</td>\n",
       "      <td>0</td>\n",
       "      <td>Gregory Nunzio Corso (March 26, 1930 – January...</td>\n",
       "      <td>Gregory Nunzio Corso March 26 1930 January 17 ...</td>\n",
       "      <td>40570</td>\n",
       "      <td>[[Beat Generation], [Beat Generation], [symbol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenore Kandel</td>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>Lenore Kandel, née le 14 janvier 1932 à New Yo...</td>\n",
       "      <td>Lenore Kandel naître 14 janvier 1932 New York ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Lenore Kandel (January 14, 1932 in New York Ci...</td>\n",
       "      <td>Lenore Kandel January 14 1932 in New York City...</td>\n",
       "      <td>5128</td>\n",
       "      <td>[[Beat Generation], [Beat Generation], [Beat G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>Louis_Guillaume</td>\n",
       "      <td>Ecole de Rochefort</td>\n",
       "      <td>Louis Guillaume (1907 - 1971) est un écrivain ...</td>\n",
       "      <td>Louis Guillaume 1907 1971 écrivain poète franç...</td>\n",
       "      <td>2</td>\n",
       "      <td>Louis Guillaume (1907 - 1971) est un écrivain ...</td>\n",
       "      <td>Louis Guillaume 1907 1971 écrivain poète franç...</td>\n",
       "      <td>5062</td>\n",
       "      <td>[[Parnasse], [pleiade], [symboliste], [symboli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Gabriel_Audisio_(romancier_et_poète)</td>\n",
       "      <td>Ecole de Rochefort</td>\n",
       "      <td>Gabriel Audisio est un écrivain et poète franç...</td>\n",
       "      <td>Gabriel Audisio écrivain poète français naître...</td>\n",
       "      <td>2</td>\n",
       "      <td>Gabriel Audisio est un écrivain et poète franç...</td>\n",
       "      <td>Gabriel Audisio écrivain poète français naître...</td>\n",
       "      <td>5139</td>\n",
       "      <td>[[Ecole de Rochefort], [Imagisme, pleiade], [s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Jean-Vincent_Verdonnet</td>\n",
       "      <td>Ecole de Rochefort</td>\n",
       "      <td>Jean-Vincent Verdonnet, né le 19 avril 1923 à ...</td>\n",
       "      <td>Verdonnet naître 19 avril 1923 Bossey décéder ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Jean-Vincent Verdonnet, né le 19 avril 1923 à ...</td>\n",
       "      <td>Verdonnet naître 19 avril 1923 Bossey décéder ...</td>\n",
       "      <td>2041</td>\n",
       "      <td>[[Ecole de Rochefort], [pleiade], [symboliste]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Alain_Robbe-Grillet</td>\n",
       "      <td>Nouveau Roman</td>\n",
       "      <td>Alain Robbe-Grillet, né le 18 août 1922 à Bres...</td>\n",
       "      <td>Alain Robbe Grillet naître 18 août 1922 brest ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Alain Robbe-Grillet, né le 18 août 1922 à Bres...</td>\n",
       "      <td>Alain Robbe Grillet naître 18 août 1922 brest ...</td>\n",
       "      <td>7079</td>\n",
       "      <td>[[Nouveau Roman], [Nouveau Roman], [symboliste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Aimé_Césaire</td>\n",
       "      <td>Négritude</td>\n",
       "      <td>Aimé Césaire, né le 26 juin 1913 à Basse-Point...</td>\n",
       "      <td>Aimé Césaire naître 26 juin 1913 Martinique mo...</td>\n",
       "      <td>9</td>\n",
       "      <td>Aimé Césaire, né le 26 juin 1913 à Basse-Point...</td>\n",
       "      <td>Aimé Césaire naître 26 juin 1913 Martinique mo...</td>\n",
       "      <td>27960</td>\n",
       "      <td>[[Négritude], [Négritude], [symboliste], [symb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Nom           Mouvement  \\\n",
       "0                    William S. Burroughs     Beat Generation   \n",
       "1                             Lucien Carr     Beat Generation   \n",
       "3                     John Clellon Holmes     Beat Generation   \n",
       "4                           Gregory Corso     Beat Generation   \n",
       "5                           Lenore Kandel     Beat Generation   \n",
       "..                                    ...                 ...   \n",
       "573                       Louis_Guillaume  Ecole de Rochefort   \n",
       "576  Gabriel_Audisio_(romancier_et_poète)  Ecole de Rochefort   \n",
       "595                Jean-Vincent_Verdonnet  Ecole de Rochefort   \n",
       "598                   Alain_Robbe-Grillet       Nouveau Roman   \n",
       "615                          Aimé_Césaire           Négritude   \n",
       "\n",
       "                                               summary  \\\n",
       "0    William Seward Burroughs (/ˈwɪljəm ˈsuɚd ˈbɜɹo...   \n",
       "1    Lucien Carr, né le 1er mars 1925 à New York et...   \n",
       "3    John Clellon Holmes est un romancier, essayist...   \n",
       "4    Gregory Nunzio Corso (New York, 26 mars 1930 -...   \n",
       "5    Lenore Kandel, née le 14 janvier 1932 à New Yo...   \n",
       "..                                                 ...   \n",
       "573  Louis Guillaume (1907 - 1971) est un écrivain ...   \n",
       "576  Gabriel Audisio est un écrivain et poète franç...   \n",
       "595  Jean-Vincent Verdonnet, né le 19 avril 1923 à ...   \n",
       "598  Alain Robbe-Grillet, né le 18 août 1922 à Bres...   \n",
       "615  Aimé Césaire, né le 26 juin 1913 à Basse-Point...   \n",
       "\n",
       "                                               sum_lem  mvm_label  \\\n",
       "0    William Seward Burroughs ˈsuɚd dit William Bur...          0   \n",
       "1    Lucien Carr naître premier mars 1925 New York ...          0   \n",
       "3    John Clellon holme romancier essayiste poète a...          0   \n",
       "4    gregory Nunzio Corso New York 26 mars 1930 Min...          0   \n",
       "5    Lenore Kandel naître 14 janvier 1932 New York ...          0   \n",
       "..                                                 ...        ...   \n",
       "573  Louis Guillaume 1907 1971 écrivain poète franç...          2   \n",
       "576  Gabriel Audisio écrivain poète français naître...          2   \n",
       "595  Verdonnet naître 19 avril 1923 Bossey décéder ...          2   \n",
       "598  Alain Robbe Grillet naître 18 août 1922 brest ...          8   \n",
       "615  Aimé Césaire naître 26 juin 1913 Martinique mo...          9   \n",
       "\n",
       "                                                  page  \\\n",
       "0    William Seward Burroughs II (; February 5, 191...   \n",
       "1    Lucien Carr (March 1, 1925 – January 28, 2005)...   \n",
       "3    John Clellon Holmes (March 12, 1926, Holyoke, ...   \n",
       "4    Gregory Nunzio Corso (March 26, 1930 – January...   \n",
       "5    Lenore Kandel (January 14, 1932 in New York Ci...   \n",
       "..                                                 ...   \n",
       "573  Louis Guillaume (1907 - 1971) est un écrivain ...   \n",
       "576  Gabriel Audisio est un écrivain et poète franç...   \n",
       "595  Jean-Vincent Verdonnet, né le 19 avril 1923 à ...   \n",
       "598  Alain Robbe-Grillet, né le 18 août 1922 à Bres...   \n",
       "615  Aimé Césaire, né le 26 juin 1913 à Basse-Point...   \n",
       "\n",
       "                                              page_lem    len  \\\n",
       "0    William Seward Burroughs ii February 5 1914 au...  61923   \n",
       "1    Lucien Carr March 1 1925 January 28 2005 was a...  18339   \n",
       "3    John Clellon Holmes March 12 1926 Holyoke Mass...   2592   \n",
       "4    Gregory Nunzio Corso March 26 1930 January 17 ...  40570   \n",
       "5    Lenore Kandel January 14 1932 in New York City...   5128   \n",
       "..                                                 ...    ...   \n",
       "573  Louis Guillaume 1907 1971 écrivain poète franç...   5062   \n",
       "576  Gabriel Audisio écrivain poète français naître...   5139   \n",
       "595  Verdonnet naître 19 avril 1923 Bossey décéder ...   2041   \n",
       "598  Alain Robbe Grillet naître 18 août 1922 brest ...   7079   \n",
       "615  Aimé Césaire naître 26 juin 1913 Martinique mo...  27960   \n",
       "\n",
       "                                                  pred  \n",
       "0    [[Beat Generation], [Beat Generation], [symbol...  \n",
       "1    [[Beat Generation], [Beat Generation, Générati...  \n",
       "3    [[Beat Generation], [Génération perdue], [Beat...  \n",
       "4    [[Beat Generation], [Beat Generation], [symbol...  \n",
       "5    [[Beat Generation], [Beat Generation], [Beat G...  \n",
       "..                                                 ...  \n",
       "573  [[Parnasse], [pleiade], [symboliste], [symboli...  \n",
       "576  [[Ecole de Rochefort], [Imagisme, pleiade], [s...  \n",
       "595  [[Ecole de Rochefort], [pleiade], [symboliste]...  \n",
       "598  [[Nouveau Roman], [Nouveau Roman], [symboliste...  \n",
       "615  [[Négritude], [Négritude], [symboliste], [symb...  \n",
       "\n",
       "[622 rows x 9 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "auteurs['pred_tf_w']=auteurs['pred'].apply(lambda L: L[0])\n",
    "auteurs['pred_tf_sum']=auteurs['pred'].apply(lambda L: L[1])\n",
    "auteurs['pred_txt_w']=auteurs['pred'].apply(lambda L: L[2])\n",
    "auteurs['pred_txt_s']=auteurs['pred'].apply(lambda L: L[3])\n",
    "\n",
    "# je mets chaque prédictions dans une seule colonne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mouvement</th>\n",
       "      <th>pred_tf_w</th>\n",
       "      <th>pred_tf_sum</th>\n",
       "      <th>pred_txt_w</th>\n",
       "      <th>pred_txt_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[symboliste]</td>\n",
       "      <td>[symboliste]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[Beat Generation, Génération perdue]</td>\n",
       "      <td>[symboliste]</td>\n",
       "      <td>[symboliste]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[Génération perdue]</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[symboliste]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[symboliste]</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beat Generation</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "      <td>[Beat Generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>Ecole de Rochefort</td>\n",
       "      <td>[Parnasse]</td>\n",
       "      <td>[pleiade]</td>\n",
       "      <td>[symboliste]</td>\n",
       "      <td>[symboliste]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Ecole de Rochefort</td>\n",
       "      <td>[Ecole de Rochefort]</td>\n",
       "      <td>[Imagisme, pleiade]</td>\n",
       "      <td>[symboliste]</td>\n",
       "      <td>[symboliste]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Ecole de Rochefort</td>\n",
       "      <td>[Ecole de Rochefort]</td>\n",
       "      <td>[pleiade]</td>\n",
       "      <td>[symboliste]</td>\n",
       "      <td>[symboliste]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Nouveau Roman</td>\n",
       "      <td>[Nouveau Roman]</td>\n",
       "      <td>[Nouveau Roman]</td>\n",
       "      <td>[symboliste]</td>\n",
       "      <td>[symboliste]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Négritude</td>\n",
       "      <td>[Négritude]</td>\n",
       "      <td>[Négritude]</td>\n",
       "      <td>[symboliste]</td>\n",
       "      <td>[symboliste]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mouvement             pred_tf_w  \\\n",
       "0       Beat Generation     [Beat Generation]   \n",
       "1       Beat Generation     [Beat Generation]   \n",
       "3       Beat Generation     [Beat Generation]   \n",
       "4       Beat Generation     [Beat Generation]   \n",
       "5       Beat Generation     [Beat Generation]   \n",
       "..                  ...                   ...   \n",
       "573  Ecole de Rochefort            [Parnasse]   \n",
       "576  Ecole de Rochefort  [Ecole de Rochefort]   \n",
       "595  Ecole de Rochefort  [Ecole de Rochefort]   \n",
       "598       Nouveau Roman       [Nouveau Roman]   \n",
       "615           Négritude           [Négritude]   \n",
       "\n",
       "                              pred_tf_sum         pred_txt_w  \\\n",
       "0                       [Beat Generation]       [symboliste]   \n",
       "1    [Beat Generation, Génération perdue]       [symboliste]   \n",
       "3                     [Génération perdue]  [Beat Generation]   \n",
       "4                       [Beat Generation]       [symboliste]   \n",
       "5                       [Beat Generation]  [Beat Generation]   \n",
       "..                                    ...                ...   \n",
       "573                             [pleiade]       [symboliste]   \n",
       "576                   [Imagisme, pleiade]       [symboliste]   \n",
       "595                             [pleiade]       [symboliste]   \n",
       "598                       [Nouveau Roman]       [symboliste]   \n",
       "615                           [Négritude]       [symboliste]   \n",
       "\n",
       "            pred_txt_s  \n",
       "0         [symboliste]  \n",
       "1         [symboliste]  \n",
       "3         [symboliste]  \n",
       "4    [Beat Generation]  \n",
       "5    [Beat Generation]  \n",
       "..                 ...  \n",
       "573       [symboliste]  \n",
       "576       [symboliste]  \n",
       "595       [symboliste]  \n",
       "598       [symboliste]  \n",
       "615       [symboliste]  \n",
       "\n",
       "[622 rows x 5 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auteurs[['Mouvement','pred_tf_w','pred_tf_sum','pred_txt_w','pred_txt_s']]\n",
    "\n",
    "#résultat plus lisibile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouveau problème (léger) dans les données. Il se trouve que Pierre a réalisé le scraping de la liste des auteurs et moi celle des mouvements et aucun de nous deux n'avait vu que certains auteurs scrapés par Pierre ne correspondaient à aucun des mouvements du tableau wiki_mouvements. Par conséquent, impossible de réaliser des prédictions correctes. \n",
    "Je vais donc les identifier et les retirer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouvements_auteurs = list(set(auteurs.Mouvement.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L=[]\n",
    "for mov in mouvements_auteurs:\n",
    "    if mov not in list(set(mouvements.mouvement)):\n",
    "        L.append(mov)\n",
    "\n",
    "        # si un mouvement est dans la liste des mouvements associés aux auteurs mais pas dans le tableau des mouvements, je le récupère dans la liste L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "auteurs['del']=auteurs.Mouvement.apply(lambda mov: int(mov in L)) \n",
    "AUT = auteurs[auteurs['del']==0] #les auteurs qui ne sont pas dans la liste décrite précédemment\n",
    "AUT=AUT[['Mouvement','pred_tf_w','pred_tf_sum','pred_txt_w','pred_txt_s']] \n",
    "#Le nouveau tableau a 559 entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-126-72f5baad327e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AUT['test']=AUT['pred_tf_w'].apply(len)\n"
     ]
    }
   ],
   "source": [
    "#AUT['test']=AUT['pred_tf_w'].apply(len)\n",
    "#AUT['Mouvement'][0]  == AUT['pred_tf_w'][0][0]\n",
    "\n",
    "#tests pour vérifier la cohérence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUT.index = [k for k in range(len(AUT))] #je réinitialise l'index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tf_w = np.array([ int(AUT['Mouvement'][k] in AUT['pred_tf_w'][k]) for k in range(559)])\n",
    "\n",
    "# je crée un np.array qui vérifie si la valeur 'Mouvement' de chaque auteur appartient au(x) mouvement(s) prédit(s) (rappel que certains mouvements)\n",
    "#peuvent être ex aequos, auquel cas on les considère tous valables). Pour chaque auteur en position k dans le tableau, \n",
    "# accuracy_tf_w[k]  vaudra 1 si c'est le cas, 0 sinon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38640429338103754"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_tf_w.sum()/559 \n",
    "\n",
    "#On réalise donc un calcul de l'accuracy : % de bonnes prédictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tf_sum = np.array([ int(AUT['Mouvement'][k] in AUT['pred_tf_sum'][k]) for k in range(559)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4525939177101968"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_tf_sum.sum()/559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_txt_w = np.array([ int(AUT['Mouvement'][k] in AUT['pred_txt_w'][k]) for k in range(559)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06976744186046512"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_txt_w.sum()/559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_txt_s = np.array([ int(AUT['Mouvement'][k] in AUT['pred_txt_s'][k]) for k in range(559)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10912343470483005"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_txt_s.sum()/559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on réalise cela pour toutes les méthodes. et on sauvegarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "auteurs.to_csv('auteurs_pred_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUT.to_csv('auteurs_pred2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
